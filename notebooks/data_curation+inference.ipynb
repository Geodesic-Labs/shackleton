{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project Shackleton - Data Curation and Deep Learning Inference\n",
    "\n",
    "In the cells below we prepare data for the Shackleton Dashboard, then run our vehicle (YOLTv5) and road (CRESI) detection algorithms on this data.  We prepare the data and execute deep learning inference in the freely available Amazon SageMaker Studio Lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 1. Create the SageMaker StudioLab environment\n",
    "\n",
    "    # install yolov5\n",
    "    # https://github.com/ultralytics/yolov5\n",
    "    cd /home/studio-lab-user\n",
    "    conda activate default\n",
    "    git clone https://github.com/ultralytics/yolov5\n",
    "    cd yolov5\n",
    "    pip install -r requirements.txt  # install\n",
    "\n",
    "    # update with geo packages\n",
    "    conda install -c conda-forge gdal\n",
    "    conda install -c conda-forge osmnx\n",
    "    conda install -c conda-forge osmnx=0.12 \n",
    "    conda install -c conda-forge scikit-image\n",
    "    conda install -c conda-forge statsmodels\n",
    "    conda install -c conda-forge matplotlib\n",
    "    conda install -c conda-forge ipykernel \n",
    "    pip install torchsummary\n",
    "    pip install utm\n",
    "    pip install numba\n",
    "    pip install jinja2==2.10\n",
    "    pip install geopandas==0.8\n",
    "    \n",
    "    # clone shackleton codebase\n",
    "    git clone https://github.com/avanetten/shackleton.git\n",
    "\n",
    "    # clone YOLTv5 and CRESI\n",
    "    cd /home/studio-lab-user/shackleton/src/\n",
    "    git clone https://github.com/avanetten/cresi.git\n",
    "    git clone https://github.com/avanetten/yoltv5.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----\n",
    "## 2. Download Data\n",
    "\n",
    "Since the pre-trained model weights are available, we need not download the SpaceNet training data.  Instead, we will just download the testing data.  For this exercise, we'll explore SpaceNet Area of Interest (AOI) \\#10: Dar Es Salaam.  This city was withheld for testing purposes in SpaceNet 5, meaning that the pre-trained model has not been trained on this city whatsoever.  To download the data (25 GB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im_raw_dir = '...'\n",
    "!aws s3 cp --recursive s3://spacenet-dataset/AOIs/AOI_10_Dar_Es_Salaam/PS-MS/ {test_im_raw_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  Prepare Test Data\n",
    "\n",
    "While CRESI is designed to handle images of arbitrary size and extent, for this exercise we will clip the image somewhat to speed processing time and ease visualization. We will also convert the 8-band multispectral 16-bit image to an easier to visualize 8-bit RGB image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the image extent\n",
    "ulx, uly, lrx, lry = 39.25252, -6.7580, 39.28430, -6.7880  # v0\n",
    "outname = 'test1_cog_clip.tif'\n",
    "im_name = [z for z in os.listdir(test_im_raw_dir) if z.endswith('.tif')][0]\n",
    "print(\"im_name:\", im_name)\n",
    "test_im_raw = os.path.join(test_im_raw_dir, im_name)\n",
    "test_im_clip = os.path.join(test_im_clip_dir, outname)\n",
    "print(\"output_file:\", test_im_clip)\n",
    "\n",
    "!gdal_translate -projwin {ulx} {uly} {lrx} {lry} {test_im_raw} {test_im_clip}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 16-bit multispectral test data to 8-bit RGB\n",
    "%cd {os.path.join(cresi_dir, 'cresi/data_prep/')}\n",
    "import create_8bit_images\n",
    "\n",
    "create_8bit_images.dir_to_8bit(test_im_clip_dir, test_final_dir,\n",
    "                              command_file_loc='',\n",
    "                              rescale_type=\"perc\",\n",
    "                              percentiles=[2,98],\n",
    "                              band_order=[5,3,2])\n",
    "\n",
    "# display our test image\n",
    "fig_width, fig_height = 16, 16\n",
    "im_test_name = [z for z in os.listdir(test_final_dir) if z.endswith('.tif')][0]\n",
    "im_test_path = os.path.join(test_final_dir, im_test_name)\n",
    "im_test = skimage.io.imread(im_test_path)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "_ = ax.imshow(im_test)\n",
    "_ = ax.set_title(im_test_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image stats for test1_cog_clip.tif: \n",
    "  - im.shape: (11770, 11111, 3)\n",
    "  - n pixels: 130,776,470\n",
    "  - Area = 11.7 km2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now ensure the image is a valid COG:\n",
    "\n",
    "%cd $test_im_clip_dir\n",
    "!gdal_translate test1_cog_clip.tif test1_realcog_clip.tif -of COG -co COMPRESS=LZW\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 3. Execute Inference\n",
    "\n",
    "Open a terminal in StudioLab, and run the following\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yoltv5\n",
    "\n",
    "    cd /home/studio-lab-user/shackleton/src/yoltv5/yoltv5\n",
    "    time ./test.sh /home/studio-lab-user/shackleton/cfg/yoltv5_8class_test_studio_lab.yaml\n",
    "    # Total time is < 1 min on a GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cresi\n",
    "\n",
    "    cd /home/studio-lab-user/shackleton/src/cresi/cresi\n",
    "    JSON=/home/studio-lab-user/shackleton/cfg/cresi_8class_test_studio_lab.json\n",
    "    time ./test.sh $JSON\n",
    "    # Total time is 2.5 minutes on a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 4. Copy Results Locally\n",
    "\n",
    "Since StudioLab cannot run a Bokeh server, we need to run the dashboard locally.  The relevant results folder in StudioLab is: /home/studio-lab-user/shackleton/results/test1.  Copy these results locally, then run the dashboard according to the README."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ox)",
   "language": "python",
   "name": "ox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
